# SumoLogic to CloudZero Adapter

A serverless adapter that extracts billing data from SumoLogic and streams it to CloudZero. This adapter processes usage data for logs, metrics, traces, and storage, converting them to CloudZero's billing format and uploading the via API.

## Overview

The adapter queries SumoLogic for usage data across different tiers and services:
- **Logs**: Continuous, Frequent, and Infrequent tiers (ingestion and scanning)
- **Storage**: Log storage and infrequent log storage (daily usage)
- **Metrics**: Datapoint ingestion
- **Traces**: Span ingestion

Data is converted to CloudZero Billing Format (CBF) and streamed to the CloudZero Anycost API.


## Environment Variables

### Required Variables

**SumoLogic Configuration:**
- `SUMO_ACCESS_KEY`: Your SumoLogic access key
- `SUMO_SECRET_KEY`: Your SumoLogic secret key
- `SUMO_DEPLOYMENT`: SumoLogic deployment (e.g., "us1", "us2", "eu", "au")
- `SUMO_ORG_ID`: Your SumoLogic organization ID

**CloudZero Configuration:**
- `CZ_AUTH_KEY`: CloudZero API authentication key
- `CZ_ANYCOST_STREAM_CONNECTION_ID`: CloudZero stream connection ID

### Optional Variables

For best results lookup your credit rates and cost per credit from your SumoLogic contract and set them using
these env variables. The defaults are not guaranteed to be correct for your contract. 

**Credit Rates (defaults shown):**
- `LOG_CONTINUOUS_CREDIT_RATE`: 20
- `LOG_FREQUENT_CREDIT_RATE`: 9
- `LOG_INFREQUENT_CREDIT_RATE`: 0.4
- `LOG_INFREQUENT_SCAN_CREDIT_RATE`: 0.016
- `METRICS_CREDIT_RATE`: 3
- `TRACING_CREDIT_RATE`: 14
- `COST_PER_CREDIT`: 0.15

**Other Options:**
- `CZ_URL`: CloudZero API endpoint (default: "https://api.cloudzero.com")
- `QUERY_TIME_HOURS`: Hours of historical data to query (default: 24, should not be changed)
- `LOGGING_LEVEL`: Log level - "INFO" or "DEBUG" (default: "INFO")

## Local Development

### Prerequisites
- Python 3.13 (or compatible version)
- [UV package manager](https://docs.astral.sh/uv/) (recommended) or pip in a pyenv
- Docker (optional for container builds)

### Setup

1. **Install dependencies:**
```bash
# Using UV (recommended)
uv sync --group dev

# Or using pip
pip install -r requirements.txt
```

2. **Configure environment variables:**

Edit test_execute.sh with your actual credentials

### Execute Locally


```bash
# Using your edited copy of the test_execute.sh script
./test_execute.sh
```


## Project Structure

```
├── sumo_anycost_lambda.py      # Main application code
├── requirements.txt            # Python dependencies (auto-generated by uv)
├── pyproject.toml             # Project configuration and dependencies
├── uv.lock                    # Lock file for reproducible builds
├── Dockerfile                 # Container image for Lambda deployment
├── create_lambda_zip.sh       # Automated Lambda zip creation script
├── test_execute.sh            # Template test script
└── README.md                  # This file
```

### Key Files

- **`sumo_anycost_lambda.py`**: Single-file application containing all logic
- **`create_lambda_zip.sh`**: Automated script to create optimized Lambda deployment packages
- **`Dockerfile`**: Production-ready container configuration for AWS Lambda
- **`pyproject.toml`**: UV config file; uses poethepoet for development task automation

## AWS Lambda Deployment

### Method 1: Using Automated ZIP Creation (Recommended)

1. **Create deployment package using the provided script:**
```bash
# The script handles everything automatically
./create_lambda_zip.sh
```

This creates `sumo-anycost-lambda.zip` (optimized for Lambda) containing:
- All dependencies from `requirements.txt` with Linux compatibility
- Main Lambda function code (renamed to `lambda_function.py`)
- Size-optimized (removes unnecessary files)
- Validates size limits


2. **Deploy with AWS CLI:**
```bash
# Create the function
aws lambda create-function \
  --function-name sumo-cz-adapter \
  --runtime python3.13 \
  --role arn:aws:iam::YOUR-ACCOUNT:role/lambda-execution-role \
  --handler lambda_function.lambda_handler \
  --zip-file fileb://sumo-anycost-lambda.zip \
  --timeout 900

# Set environment variables
aws lambda update-function-configuration \
  --function-name sumo-cz-adapter \
  --environment Variables='{
    "SUMO_ACCESS_KEY":"your-key",
    "SUMO_SECRET_KEY":"your-secret",
    "SUMO_DEPLOYMENT":"us1",
    "SUMO_ORG_ID":"your-org-id",
    "CZ_AUTH_KEY":"your-cz-key",
    "CZ_ANYCOST_STREAM_CONNECTION_ID":"your-stream-id"
  }'
```

Note: You can also deploy the zip file through the AWS Lambda UI. Don't forget to set the environmental variables 
(see test_execute.sh for all available variables.) It is recommended to set your AWS Lambda function timeout to
15 minutes (900 seconds) as this script can take a while to complete. 

### Method 2: Using Container Image

The repository includes a production-ready `Dockerfile` using AWS Lambda Python 3.13 base image.

1. **Build the Docker image:**
```bash
# Build image using provided Dockerfile
docker build -t sumo-cz-adapter .
```

2. **Push to Amazon ECR and deploy:**
```bash
# Create ECR repository
aws ecr create-repository --repository-name sumo-cz-adapter

# Get ECR login token
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin YOUR-ACCOUNT.dkr.ecr.us-east-1.amazonaws.com

# Tag and push image
docker tag sumo-cz-adapter:latest YOUR-ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/sumo-cz-adapter:latest
docker push YOUR-ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/sumo-cz-adapter:latest

# Create Lambda function using container image
aws lambda create-function \
  --function-name sumo-cz-adapter \
  --package-type Image \
  --code ImageUri=YOUR-ACCOUNT.dkr.ecr.us-east-1.amazonaws.com/sumo-cz-adapter:latest \
  --role arn:aws:iam::YOUR-ACCOUNT:role/lambda-execution-role \
  --timeout 300 \
  --environment Variables='{
    "SUMO_ACCESS_KEY":"your-key",
    "SUMO_SECRET_KEY":"your-secret",
    "SUMO_DEPLOYMENT":"us1",
    "SUMO_ORG_ID":"your-org-id",
    "CZ_AUTH_KEY":"your-cz-key",
    "CZ_ANYCOST_STREAM_CONNECTION_ID":"your-stream-id"
  }'
```

### Scheduling

**IMPORTANT:** This script must be run exactly once every 24 hours. Running it at any other frequency will cause incorrect data reporting.

Set up EventBridge to run daily:
```bash
aws events put-rule \
  --name sumo-cz-adapter-daily \
  --schedule-expression "rate(24 hours)"

aws lambda add-permission \
  --function-name sumo-cz-adapter \
  --statement-id allow-eventbridge \
  --action lambda:InvokeFunction \
  --principal events.amazonaws.com \
  --source-arn arn:aws:events:us-east-1:YOUR-ACCOUNT:rule/sumo-cz-adapter-daily
```

## Azure Functions Deployment (untested)

### Prerequisites
```bash
# Install Azure Functions Core Tools
npm install -g azure-functions-core-tools@4

# Install Azure CLI
# https://docs.microsoft.com/en-us/cli/azure/install-azure-cli
```

### Deployment Steps

1. **Create function app structure:**
```bash
# Initialize function app
func init SumoCZAdapter --python --model V2

cd SumoCZAdapter

# Create HTTP trigger function
func new --name SumoCZFunction --template "Timer trigger" --authlevel anonymous
```

2. **Update `requirements.txt`:**
```txt
requests==2.32.4
azure-functions
```

3. **Replace `function_app.py` content:**
```python
import azure.functions as func
import logging
from sumo_anycost_lambda import lambda_handler

app = func.FunctionApp()

@app.schedule(schedule="0 0 0 * * *", arg_name="myTimer", run_on_startup=False)
def timer_trigger(myTimer: func.TimerRequest) -> None:
    if myTimer.past_due:
        logging.info('The timer is past due!')
    
    lambda_handler({}, {})
    logging.info('SumoLogic to CloudZero sync completed')
```

4. **Copy your main file:**
```bash
cp ../sumo_anycost_lambda.py .
```

5. **Deploy:**
```bash
# Create resource group
az group create --name rg-sumo-cz-adapter --location eastus

# Create storage account
az storage account create \
  --name sumoczadapterstorage \
  --location eastus \
  --resource-group rg-sumo-cz-adapter \
  --sku Standard_LRS

# Create function app
az functionapp create \
  --resource-group rg-sumo-cz-adapter \
  --consumption-plan-location eastus \
  --runtime python \
  --runtime-version 3.10 \
  --functions-version 4 \
  --name sumo-cz-adapter \
  --storage-account sumoczadapterstorage

# Deploy function
func azure functionapp publish sumo-cz-adapter

# Set environment variables
az functionapp config appsettings set \
  --name sumo-cz-adapter \
  --resource-group rg-sumo-cz-adapter \
  --settings \
    SUMO_ACCESS_KEY="your-key" \
    SUMO_SECRET_KEY="your-secret" \
    SUMO_DEPLOYMENT="us1" \
    SUMO_ORG_ID="your-org-id" \
    CZ_AUTH_KEY="your-cz-key" \
    CZ_ANYCOST_STREAM_CONNECTION_ID="your-stream-id"
```

## Google Cloud Functions Deployment (untested)

### Prerequisites
```bash
# Install Google Cloud CLI
# https://cloud.google.com/sdk/docs/install

# Authenticate
gcloud auth login
gcloud config set project YOUR-PROJECT-ID
```

### Deployment Steps

1. **Create `requirements.txt`:**
```txt
requests==2.32.4
functions-framework
```

2. **Create `main.py` wrapper:**
```python
import functions_framework
from sumo_anycost_lambda import lambda_handler

@functions_framework.cloud_event
def sumo_cz_sync(cloud_event):
    lambda_handler({}, {})
    return "Sync completed"
```

3. **Deploy function:**
```bash
# Deploy with Cloud Scheduler trigger (daily)
gcloud functions deploy sumo-cz-adapter \
  --gen2 \
  --runtime python310 \
  --source . \
  --entry-point sumo_cz_sync \
  --trigger-topic sumo-cz-trigger \
  --timeout 300 \
  --memory 256MB \
  --set-env-vars \
    SUMO_ACCESS_KEY="your-key",\
    SUMO_SECRET_KEY="your-secret",\
    SUMO_DEPLOYMENT="us1",\
    SUMO_ORG_ID="your-org-id",\
    CZ_AUTH_KEY="your-cz-key",\
    CZ_ANYCOST_STREAM_CONNECTION_ID="your-stream-id"
```

4. **Create Cloud Scheduler job:**
```bash
# Create topic for scheduling
gcloud pubsub topics create sumo-cz-trigger

# Create daily scheduled job (IMPORTANT: Must run exactly once every 24 hours)
gcloud scheduler jobs create pubsub sumo-cz-daily \
  --schedule="0 0 * * *" \
  --topic=sumo-cz-trigger \
  --message-body="{}"
```

### Alternative: HTTP Trigger

For HTTP-triggered deployment:

1. **Create `main.py` with HTTP trigger:**
```python
import functions_framework
from sumo_anycost_lambda import lambda_handler

@functions_framework.http
def sumo_cz_sync(request):
    lambda_handler({}, {})
    return "Sync completed"
```

2. **Deploy:**
```bash
gcloud functions deploy sumo-cz-adapter \
  --gen2 \
  --runtime python310 \
  --source . \
  --entry-point sumo_cz_sync \
  --trigger-http \
  --allow-unauthenticated \
  --timeout 300
```

## Dependency Management Notes

**AWS Lambda:**
- Use `pip install -t .` to install packages in the deployment directory
- Or use container images with pip install in Dockerfile
- requests library is not included in Lambda runtime by default

**Azure Functions:**
- Dependencies in `requirements.txt` are automatically installed
- requests library is not included by default

**Google Cloud Functions:**
- Dependencies in `requirements.txt` are automatically installed during deployment
- requests library is not included in runtime by default

## Monitoring and Troubleshooting

### Logging
- Set `LOGGING_LEVEL=DEBUG` for detailed logging output
- All API calls are logged with debug information
- Storage filtering shows which date is being processed

### Common Issues

**Function Timeout:**
- Minimum timeout: 300 seconds (5 minutes)
- SumoLogic export API can take time to generate reports
- Consider increasing timeout for large data volumes

**Rate Limiting:**
- Adapter includes exponential backoff for 429 errors
- Monitor CloudWatch logs for rate limiting patterns
- SumoLogic API has rate limits per minute

**Date Parsing Errors:**
- Fixed in current version with flexible date parsing
- Handles both MM/dd/yy and ISO date formats from SumoLogic

**Empty Results:**
- Storage filtering may return no data if previous day has no usage
- Verify SumoLogic organization has data for the date range
- Check SUMO_ORG_ID matches your organization

**CloudZero Stream Errors:**
- Verify CZ_ANYCOST_STREAM_CONNECTION_ID is correct
- Check CloudZero API authentication
- Monitor for 4xx/5xx responses in logs

### Testing
```bash
# Test with debug logging
export LOGGING_LEVEL=DEBUG
./test_execute.sh

# Check zip file contents
unzip -l sumo-anycost-lambda.zip

# Validate Docker build
docker build -t test-adapter . && docker images test-adapter
```

## Security Considerations

- Store API keys and secrets in your cloud provider's secret management service
- Use IAM roles with minimal required permissions
- Enable function logging and monitoring
- Consider VPC deployment for enhanced security